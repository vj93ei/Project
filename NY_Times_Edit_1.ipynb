{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting & Storing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting data from Article search API\n",
    "import requests\n",
    "import json\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=0\n",
      "<Response [200]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=1\n",
      "<Response [200]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=2\n",
      "<Response [200]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=3\n",
      "<Response [200]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=4\n",
      "<Response [200]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=5\n",
      "<Response [200]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=6\n",
      "<Response [200]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=7\n",
      "<Response [200]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=8\n",
      "<Response [200]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=9\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=10\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=11\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=12\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=13\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=14\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=15\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=16\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=17\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=18\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=19\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=20\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=21\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=22\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=23\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=24\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=25\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=26\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=27\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=28\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=29\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=30\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=31\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=32\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=33\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=34\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=35\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=36\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=37\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=38\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=39\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=40\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=41\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=42\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=43\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=44\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=45\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=46\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=47\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=48\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=49\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=50\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=51\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=52\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=53\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=54\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=55\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=56\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=57\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=58\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=59\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=60\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=61\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=62\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=63\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=64\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=65\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=67\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=68\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=69\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=70\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=71\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=72\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=73\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=74\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=75\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=76\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=77\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=78\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=79\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=80\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=81\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=82\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=83\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=84\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=85\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=86\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=87\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=88\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=89\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=90\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=91\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=92\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=93\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=94\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=95\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=96\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=97\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=98\n",
      "<Response [429]>\n",
      "https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=99\n"
     ]
    }
   ],
   "source": [
    "import requests                                             #importing requests module for making calls to the api\n",
    "import json                                                 #importing json to write data directly to json files\n",
    "import os                                                   #importing os fetch the value of environment variable\n",
    "import time                                                 #importing time module to use sleep function\n",
    "#print(os.environ.get('eM9pJBt0x9DYvJBU'))\n",
    "#print(os.getenv('V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD', default_value))\n",
    "for i in range (0,100):                                     #looping to get data from different pages\n",
    "    apikey_parameter={'api-key':'V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD','page':i}\n",
    "    #print(apikey_parameter)\n",
    "                                                            #different paramenters which are to be passed as query string\n",
    "    #time.sleep(4)                                           #keeping  4 secs delay between each call to the api\n",
    "    response_articlesearch=requests.get('https://api.nytimes.com/svc/search/v2/articlesearch.json',params=apikey_parameter)\n",
    "                                                            #getting responses on the get request\n",
    "    print(response_articlesearch)                           #printing the reponse to check if it is ok\n",
    "    print(response_articlesearch.url)                       #printing the url\n",
    "    \n",
    "    with open(\"data/article_search/response_articlesearch_data\"+str(i)+\".json\",\"a\") as Response_data:\n",
    "        json.dump(response_articlesearch.json(),Response_data)\n",
    "                                                            #writing data to the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting data from Archive API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "https://api.nytimes.com/svc/archive/v1/2019/1.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=0\n",
      "<Response [200]>\n",
      "https://api.nytimes.com/svc/archive/v1/2019/1.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=1\n",
      "<Response [200]>\n",
      "https://api.nytimes.com/svc/archive/v1/2019/1.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=2\n",
      "<Response [200]>\n",
      "https://api.nytimes.com/svc/archive/v1/2019/1.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=3\n",
      "<Response [200]>\n",
      "https://api.nytimes.com/svc/archive/v1/2019/1.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=4\n",
      "<Response [200]>\n",
      "https://api.nytimes.com/svc/archive/v1/2019/1.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=5\n",
      "<Response [200]>\n",
      "https://api.nytimes.com/svc/archive/v1/2019/1.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=6\n",
      "<Response [200]>\n",
      "https://api.nytimes.com/svc/archive/v1/2019/1.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=7\n",
      "<Response [200]>\n",
      "https://api.nytimes.com/svc/archive/v1/2019/1.json?api-key=V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD&page=8\n"
     ]
    }
   ],
   "source": [
    "import requests                                             #importing requests module for making calls to the api\n",
    "import json                                                 #importing json to write data directly to json files\n",
    "import os                                                   #importing os fetch the value of environment variable\n",
    "import time                                                 #importing time module to use sleep function\n",
    "\n",
    "for i in range (0,9):                                     #looping to get data from different pages\n",
    "    apikey_parameter={'api-key':'V3nM7Z3JxoChO8UnrMVE2icZfCH4rBfD','page':i}\n",
    "                                                            #different paramenters which are to be passed as query string\n",
    "    #time.sleep(4)                                           #keeping  4 secs delay between each call to the api\n",
    "    \n",
    "    response_archive=requests.get('https://api.nytimes.com/svc/archive/v1/2019/1.json',params=apikey_parameter)\n",
    "                                                            #getting responses on the get request\n",
    "    print(response_archive)                                 #printing the reponse to check if it is ok\n",
    "    print(response_archive.url)                             #printing the url\n",
    "    with open(\"data/Archive/response_archive\"+str(i)+\"json\",\"a\") as Response_data:\n",
    "                                                            #opening a json file in append mode\n",
    "        json.dump(response_archive.json(),Response_data)\n",
    "                                                            #writing data to the json file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting unique article section names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'response'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-73487b508269>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m:\u001b[0m                                \u001b[1;31m#opening each files and giving alias as r\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mjson_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m                             \u001b[1;31m#loading the data of each file into json_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mjson_response\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'response'\u001b[0m\u001b[1;33m]\u001b[0m                  \u001b[1;31m#getting response from each page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mjson_docs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson_response\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'docs'\u001b[0m\u001b[1;33m]\u001b[0m                      \u001b[1;31m#getting all articles from every page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjson_docs\u001b[0m\u001b[1;33m:\u001b[0m                                \u001b[1;31m#iterating over articles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'response'"
     ]
    }
   ],
   "source": [
    "from glob import glob                                        #importing glob library\n",
    "list_sections = [];                                          #empty list to store different categories by section_name\n",
    "import json\n",
    "\n",
    "d={}                                                         #empty dictionary to store section_name n counts\n",
    "for filename in glob('data/article_search/*.json'):          #iterrating over all the json files in data folder\n",
    "    with open(filename) as r:                                #opening each files and giving alias as r\n",
    "        json_data = json.load(r)                             #loading the data of each file into json_data\n",
    "        json_response=json_data['response']                  #getting response from each page\n",
    "        json_docs=json_response['docs']                      #getting all articles from every page\n",
    "        for doc in json_docs:                                #iterating over articles\n",
    "            if doc['section_name'] not in list_sections:  \n",
    "                list_sections.append(doc['section_name'])\n",
    "for i in range(0,len(list_sections)):\n",
    "    count=0\n",
    "    for filename in glob('data/article_search/*.json'):      #iterrating over all the json files in data folder\n",
    "        with open(filename) as r:                            #opening each files and giving alias as r\n",
    "            json_data = json.load(r)                         #loading the data of each file into json_data\n",
    "            json_response=json_data['response']\n",
    "            json_docs=json_response['docs']\n",
    "            for doc in json_docs:\n",
    "                if doc['section_name']==list_sections[i]:    #recording the count of articles for each section_name\n",
    "                    count+=1\n",
    "                    d[doc['section_name']]=count\n",
    "#print(\"Number of articles for each section\")\n",
    "#print(d)                                                     #printing each section name\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "xaxis=[];\n",
    "yaxis=[];\n",
    "for c in d.items():\n",
    "    xaxis.append(c[0])\n",
    "    yaxis.append(c[1])\n",
    "plotly.tools.set_credentials_file(username='vraveend',api_key='mGQQTX4cETrZF96pGMhc')\n",
    "data = [go.Bar(\n",
    "            x=xaxis,\n",
    "            y=yaxis\n",
    "    )]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Graph to analyze top 5/famous sections of NYT',\n",
    "    xaxis=dict(\n",
    "        title='category of articles',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=22,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Number of Articles',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=22,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the maximum number of articles are on world's news.So the world's news articles can be analyzed closely to get further information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing what all subsections different sections have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'subsection_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-e34b503ba29c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjson_docs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'section_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0meach_sec\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                         \u001b[1;32mif\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'subsection_name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_subsections\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                             \u001b[0mlist_subsections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'subsection_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meach_sec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'subsection_name'"
     ]
    }
   ],
   "source": [
    "for each_sec in list_sections:\n",
    "    list_subsections=[]\n",
    "    for filename in glob('data/article_search/*.json'):          #iterrating over all the json files in data folder\n",
    "        with open(filename) as r:                                #opening each files and giving alias as r\n",
    "            json_data = json.load(r)                             #loading the data of each file into json_data\n",
    "            json_response=json_data['response']\n",
    "            json_docs=json_response['docs']\n",
    "            for doc in json_docs:\n",
    "                    if doc['section_name']==each_sec:\n",
    "                        if doc['subsection_name'] not in list_subsections:\n",
    "                            list_subsections.append(doc['subsection_name'])\n",
    "    print(each_sec)\n",
    "    print(list_subsections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing subsections of world section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'response'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-fbc50c490335>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m:\u001b[0m                            \u001b[1;31m#opening each files and giving alias as r\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mjson_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m                         \u001b[1;31m#loading the data of each file into json_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mjson_response\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'response'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mjson_docs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson_response\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'docs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjson_docs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'response'"
     ]
    }
   ],
   "source": [
    "list_subsecs=['Middle East', 'Asia Pacific', 'Europe', 'Africa', 'Americas', None, 'Canada']\n",
    "dsubsec={}\n",
    "for i_in in range(len(list_subsecs)):\n",
    "    count=0\n",
    "    for filename in glob('data/article_search/*.json'):      #iterrating over all the json files in data folder\n",
    "        with open(filename) as r:                            #opening each files and giving alias as r\n",
    "            json_data = json.load(r)                         #loading the data of each file into json_data\n",
    "            json_response=json_data['response']\n",
    "            json_docs=json_response['docs']\n",
    "            for doc in json_docs:\n",
    "                if doc['section_name']==\"World\":         #recording the count of articles for each section_name\n",
    "                    if doc['subsection_name']==list_subsecs[i_in]:\n",
    "                        count+=1\n",
    "                        dsubsec[doc['subsection_name']]=count \n",
    "#print(\"World\")\n",
    "regions=[]\n",
    "aricles_region=[]\n",
    "for d_sub in dsubsec.items():\n",
    "#    print(d_sub)\n",
    "    regions.append(d_sub[0])\n",
    "    aricles_region.append(d_sub[1])\n",
    "\n",
    "#print(regions)\n",
    "#print(aricles_region)\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "fig = {\n",
    "    'data': [{'labels': regions,\n",
    "              'values': aricles_region,\n",
    "              'type': 'pie'}],\n",
    "    'layout': {'title': 'most talked about countries/regions in New York Times'}\n",
    "     }\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that under world section category, Europe subsection has the maximum number of articles. We can deep dive into the main headlines of Europe subcategory to know more about its articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all the headlines for section -> World and subsection-> Europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'response'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-115-2cf240274477>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m:\u001b[0m                            \u001b[1;31m#opening each files and giving alias as r\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mjson_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m                         \u001b[1;31m#loading the data of each file into json_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mjson_response\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'response'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mjson_docs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson_response\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'docs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjson_docs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'response'"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "counter=0\n",
    "headlines=[]\n",
    "for filename in glob('data/article_search/*.json'):      #iterrating over all the json files in data folder\n",
    "    with open(filename) as r:                            #opening each files and giving alias as r\n",
    "        json_data = json.load(r)                         #loading the data of each file into json_data\n",
    "        json_response=json_data['response']\n",
    "        json_docs=json_response['docs']\n",
    "        for doc in json_docs:\n",
    "            if doc['section_name']==\"World\":             #recording the count of articles for each section_name\n",
    "                if doc['subsection_name']==\"Europe\":\n",
    "                    headl=doc['headline']\n",
    "                    print_headline=headl['main']\n",
    "                    headlines.append(print_headline)\n",
    "                    counter+=1;\n",
    "                \n",
    "headline_text=' '.join(headlines)                        #joining all headlines to form a single text\n",
    "string_punctuation = string.punctuation\n",
    "ignoreChar=['\\r','\\n','',' ',\"'s\"]\n",
    "nums=['0','1','2','3','4','5','6','7','8','9']\n",
    "headlines_data = nltk.word_tokenize(headline_text)\n",
    "words_only = [l.lower() for l in headlines_data if l not in string_punctuation if l not in ignoreChar if l not in nums]\n",
    "filtered_headlines_data=[word for word in words_only if word not in stopwords.words('english')]\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "counts=Counter([wnl.lemmatize(data) for data in filtered_headlines_data])\n",
    "commn_words=[]\n",
    "freq=[]\n",
    "for a in counts.most_common(30):\n",
    "    commn_words.append(a[0])\n",
    "    freq.append(a[1])\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'freq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-3228807a0f0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m trace0 = go.Scatter(\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcommn_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'markers'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'freq' is not defined"
     ]
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "trace0 = go.Scatter(\n",
    "    x=freq,\n",
    "    y=commn_words,\n",
    "    mode='markers',\n",
    "    name='word frequency graph',\n",
    "    marker=dict(\n",
    "        color='rgba(156, 165, 196, 0.95)',\n",
    "        line=dict(\n",
    "            color='rgba(156, 165, 196, 1.0)',\n",
    "            width=.5,\n",
    "        ),\n",
    "        symbol='circle',\n",
    "        size=10,\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace0]\n",
    "layout = go.Layout(\n",
    "    title=\"frequency of top 50 words from articles where section is World and subsection is Europe\",\n",
    "    xaxis=dict(\n",
    "        showgrid=False,\n",
    "        showline=True,\n",
    "        linecolor='rgb(102, 102, 102)',\n",
    "        titlefont=dict(\n",
    "            color='rgb(204, 204, 204)'\n",
    "        ),\n",
    "        tickfont=dict(\n",
    "            color='rgb(102, 102, 102)',\n",
    "        ),\n",
    "        autotick=False,\n",
    "        dtick=1,\n",
    "        ticks='outside',\n",
    "        tickcolor='rgb(102, 102, 102)',\n",
    "    ),\n",
    "    margin=dict(\n",
    "        l=150,\n",
    "        r=70,\n",
    "        b=50,\n",
    "        t=80\n",
    "    ),\n",
    "    legend=dict(\n",
    "        font=dict(\n",
    "            size=10,\n",
    "        ),\n",
    "        yanchor='middle',\n",
    "        xanchor='right',\n",
    "    ),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    paper_bgcolor='rgb(254, 247, 234)',\n",
    "    plot_bgcolor='rgb(254, 247, 234)',\n",
    "    hovermode='closest',\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='word-freq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we can see that the most talked words in the articles for Erope includes \"say,French,Talk,turkey,ireland,syria,german\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis - 2 (Sentiment Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis on the headlines for Europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-31640f7ee27b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentiments\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNaiveBayesAnalyzer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpos_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mneg_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "\n",
    "pos_count = 0\n",
    "neg_count = 0\n",
    "for sentence in headlines:\n",
    "    blob = TextBlob(sentence, analyzer=NaiveBayesAnalyzer())\n",
    "    print(sentence)\n",
    "    print(blob.sentiment)\n",
    "    print('*****************************************************************************************')\n",
    "    if blob.sentiment.classification == 'pos':\n",
    "        pos_count+=1\n",
    "    if blob.sentiment.classification == 'neg':\n",
    "        neg_count+=1\n",
    "print('Total postive counts:')\n",
    "print(pos_count)\n",
    "print('Total negative counts:')\n",
    "print(neg_count)\n",
    "Total = pos_count + neg_count\n",
    "def percentage(part, whole):\n",
    "    return 100 * float(part)/float(whole)\n",
    "neg_percent = percentage(neg_count, Total)\n",
    "pos_percent = percentage(pos_count, Total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all the articles on Europe total positive count is 97 and total negative coint of articles is 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Archive API data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching unique years for which we have data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from glob import glob                                        #importing glob library\n",
    "list_push_Year_month=[]\n",
    "import json\n",
    "                    \n",
    "for filename in glob('data/Archive/*.json'):                 #iterrating over all the json files in data folder\n",
    "    with open(filename) as r:                                #opening each files and giving alias as r\n",
    "        json_data = json.load(r)                             #loading the data of each file into json_data\n",
    "        json_response=json_data['response']                  #getting response from each page\n",
    "        json_docs=json_response['docs']                      #getting all articles from every page\n",
    "        for doc in json_docs:                                #iterating over articles\n",
    "            if doc['pub_date'][:7] not in list_push_Year_month:\n",
    "                list_push_Year_month.append(doc['pub_date'][:7])\n",
    "            \n",
    "print(list_push_Year_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch unique section names for all years and their count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016_09\n",
      "[]\n",
      "2016_10\n",
      "{}\n",
      "2016_11\n",
      "{}\n",
      "2016_12\n",
      "{}\n",
      "2017_01\n",
      "{}\n",
      "2017_02\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "from glob import glob                                        #importing glob library\n",
    "list_sections_2016_09 = {};                                  #empty list to store different categories by section_name\n",
    "list_sections_2016_10 = {}; \n",
    "list_sections_2016_11 = {}; \n",
    "list_sections_2016_12 = {};\n",
    "list_sections_2017_01 = {};\n",
    "list_sections_2017_02 = {}; \n",
    "import json\n",
    "                                                \n",
    "for filename in glob('data/Archive/*.json'):                 #iterrating over all the json files in data folder\n",
    "    with open(filename) as r:                                #opening each files and giving alias as r\n",
    "        json_data = json.load(r)                             #loading the data of each file into json_data\n",
    "        json_response=json_data['response']                  #getting response from each page\n",
    "        json_docs=json_response['docs']                      #getting all articles from every page\n",
    "        for doc in json_docs:                                #iterating over articles\n",
    "            if doc['pub_date'][:7]=='2016-09':\n",
    "                if doc['section_name'] not in list_sections_2016_09:  \n",
    "                    list_sections_2016_09[doc['section_name']]=1\n",
    "                else:\n",
    "                     list_sections_2016_09[doc['section_name']]+=1\n",
    "            if doc['pub_date'][:7]=='2016-10':\n",
    "                if doc['section_name'] not in list_sections_2016_10:  \n",
    "                    list_sections_2016_10[doc['section_name']]=1\n",
    "                else:\n",
    "                     list_sections_2016_10[doc['section_name']]+=1\n",
    "            if doc['pub_date'][:7]=='2016-11':\n",
    "                if doc['section_name'] not in list_sections_2016_11:  \n",
    "                    list_sections_2016_11[doc['section_name']]=1\n",
    "                else:\n",
    "                     list_sections_2016_11[doc['section_name']]+=1\n",
    "            if doc['pub_date'][:7]=='2016-12':\n",
    "                if doc['section_name'] not in list_sections_2016_12:  \n",
    "                    list_sections_2016_12[doc['section_name']]=1\n",
    "                else:\n",
    "                     list_sections_2016_12[doc['section_name']]+=1\n",
    "            if doc['pub_date'][:7]=='2017-01':\n",
    "                if doc['section_name'] not in list_sections_2017_01:  \n",
    "                    list_sections_2017_01[doc['section_name']]=1\n",
    "                else:\n",
    "                     list_sections_2017_01[doc['section_name']]+=1\n",
    "            if doc['pub_date'][:7]=='2017-02':\n",
    "                if doc['section_name'] not in list_sections_2017_02:  \n",
    "                    list_sections_2017_02[doc['section_name']]=1\n",
    "                else:\n",
    "                     list_sections_2017_02[doc['section_name']]+=1\n",
    "                    \n",
    "print(\"2016_09\")\n",
    "print(Counter(list_sections_2016_09).most_common(5))\n",
    "print(\"2016_10\")\n",
    "print(list_sections_2016_10)\n",
    "print(\"2016_11\")\n",
    "print(list_sections_2016_11)\n",
    "print(\"2016_12\")\n",
    "print(list_sections_2016_12)\n",
    "print(\"2017_01\")\n",
    "print(list_sections_2017_01)\n",
    "print(\"2017_02\")\n",
    "print(list_sections_2017_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching top 5 sections for 2016_09 and analyzing their trend over 6 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016_09\n",
      "[]\n",
      "2016_10\n",
      "[]\n",
      "2016_11\n",
      "[]\n",
      "2016_12\n",
      "[]\n",
      "2017_01\n",
      "[]\n",
      "2017_02\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "top5_2016_09={}\n",
    "top5_2016_10={}\n",
    "top5_2016_11={}\n",
    "top5_2016_12={}\n",
    "top5_2017_01={}\n",
    "top5_2017_02={}\n",
    "sections=[]\n",
    "print(\"2016_09\")\n",
    "for each_sec_09 in Counter(list_sections_2016_09).most_common(5):\n",
    "    top5_2016_09[each_sec_09[0]]=each_sec_09[1]\n",
    "print(sorted(top5_2016_09.items()))\n",
    "for each_sec in sorted(top5_2016_09.items()):\n",
    "    sections.append(each_sec[0])\n",
    "print(\"2016_10\")\n",
    "for x in list_sections_2016_10.items():\n",
    "    for y in Counter(list_sections_2016_09).most_common(5):\n",
    "        if x[0]==y[0]:\n",
    "            top5_2016_10[x[0]]=x[1]\n",
    "print(sorted(top5_2016_10.items()))\n",
    "print(\"2016_11\")\n",
    "for x in list_sections_2016_11.items():\n",
    "    for y in Counter(list_sections_2016_09).most_common(5):\n",
    "        if x[0]==y[0]:\n",
    "            top5_2016_11[x[0]]=x[1]\n",
    "print(sorted(top5_2016_11.items()))\n",
    "print(\"2016_12\")\n",
    "for x in list_sections_2016_12.items():\n",
    "    for y in Counter(list_sections_2016_09).most_common(5):\n",
    "        if x[0]==y[0]:\n",
    "            top5_2016_12[x[0]]=x[1]\n",
    "print(sorted(top5_2016_12.items()))\n",
    "print(\"2017_01\")\n",
    "for x in list_sections_2017_01.items():\n",
    "    for y in Counter(list_sections_2016_09).most_common(5):\n",
    "        if x[0]==y[0]:\n",
    "            top5_2017_01[x[0]]=x[1]\n",
    "print(sorted(top5_2017_01.items()))\n",
    "print(\"2017_02\")\n",
    "for x in list_sections_2017_02.items():\n",
    "    for y in Counter(list_sections_2016_09).most_common(5):\n",
    "        if x[0]==y[0]:\n",
    "            top5_2017_02[x[0]]=x[1]\n",
    "print(sorted(top5_2017_02.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a graph to analyze the trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Arts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-139-a88fbe20157f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0marts_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtop5_2016_09\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Arts'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2016_10\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Arts'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2016_11\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Arts'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2016_12\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Arts'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2017_01\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Arts'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2017_02\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Arts'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfns_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtop5_2016_09\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Fashion & Style'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2016_10\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Fashion & Style'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2016_11\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Fashion & Style'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2016_12\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Fashion & Style'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2017_01\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Fashion & Style'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2017_02\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Fashion & Style'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mopinion_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtop5_2016_09\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Opinion'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2016_10\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Opinion'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2016_11\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Opinion'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2016_12\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Opinion'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2017_01\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Opinion'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2017_02\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Opinion'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mUS_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtop5_2016_09\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'U.S.'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2016_10\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'U.S.'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2016_11\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'U.S.'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2016_12\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'U.S.'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2017_01\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'U.S.'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2017_02\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'U.S.'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mworld_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtop5_2016_09\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'World'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2016_10\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'World'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2016_11\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'World'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2016_12\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'World'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2017_01\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'World'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop5_2017_02\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'World'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Arts'"
     ]
    }
   ],
   "source": [
    "arts_data=[top5_2016_09['Arts'],top5_2016_10['Arts'],top5_2016_11['Arts'],top5_2016_12['Arts'],top5_2017_01['Arts'],top5_2017_02['Arts']]\n",
    "fns_data=[top5_2016_09['Fashion & Style'],top5_2016_10['Fashion & Style'],top5_2016_11['Fashion & Style'],top5_2016_12['Fashion & Style'],top5_2017_01['Fashion & Style'],top5_2017_02['Fashion & Style']]\n",
    "opinion_data=[top5_2016_09['Opinion'],top5_2016_10['Opinion'],top5_2016_11['Opinion'],top5_2016_12['Opinion'],top5_2017_01['Opinion'],top5_2017_02['Opinion']]\n",
    "US_data=[top5_2016_09['U.S.'],top5_2016_10['U.S.'],top5_2016_11['U.S.'],top5_2016_12['U.S.'],top5_2017_01['U.S.'],top5_2017_02['U.S.']]\n",
    "world_data=[top5_2016_09['World'],top5_2016_10['World'],top5_2016_11['World'],top5_2016_12['World'],top5_2017_01['World'],top5_2017_02['World']]\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "trace1 = go.Bar(\n",
    "    x=list_push_Year_month,\n",
    "    y=arts_data,\n",
    "    name='Arts'\n",
    ")\n",
    "trace2 = go.Bar(\n",
    "    x=list_push_Year_month,\n",
    "    y=fns_data,\n",
    "    name='Fashion & Style'\n",
    ")\n",
    "trace3 = go.Bar(\n",
    "    x=list_push_Year_month,\n",
    "    y=opinion_data,\n",
    "    name='Opinion'\n",
    ")\n",
    "trace4 = go.Bar(\n",
    "    x=list_push_Year_month,\n",
    "    y=US_data,\n",
    "    name='U.S.'\n",
    ")\n",
    "trace5 = go.Bar(\n",
    "    x=list_push_Year_month,\n",
    "    y=world_data,\n",
    "    name='World'\n",
    ")\n",
    "data = [trace1, trace2, trace3, trace4, trace5]\n",
    "layout = go.Layout(\n",
    "    barmode='group'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows the trend of top 5 sections of articles from Sep 2016 to feb 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
